{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CatDog classification Task"
      ],
      "metadata": {
        "id": "nL7zrKZQxow_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 실습에서는 Kaggle에서 제공하는 cat & dog classification을 수행할 것입니다. \n",
        "<br>\n",
        "여러분은 이 Task를 수행하기 위한 모든 것을 이미 다 배웠습니다! 무엇이 필요한지는 제가 하나하나 다 말씀 드릴테니 직접 찾아서 수행해보시기 바랍니다"
      ],
      "metadata": {
        "id": "-fBwtwlvxVq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Download"
      ],
      "metadata": {
        "id": "AAkzU0H5xtYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "해당 데이터셋은 https://www.kaggle.com/competitions/dogs-vs-cats/data 여기에서 찾아보실 수 있습니다. Kaggle API를 이용해서 직접 다운 받아주세요!\n",
        "<br>\n",
        "**Hint : basic_wk6**"
      ],
      "metadata": {
        "id": "0XjOeJ4cx2eg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v9g1h9a1pBwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "M_wgNnAlyPnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 다운받은 데이터셋을 압축 해제하자.\n",
        "<br>\n",
        "**Hint : basic_wk6**"
      ],
      "metadata": {
        "id": "9OAjeVoknz0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_directory = \"C:/Users/Unity/Downloads/dogs-vs-cats\"\n",
        "\n",
        "dataset_directory = \"C:/Users/Unity/Downloads/CatDog\"\n",
        "\n",
        "\n",
        "dataset_zip = zipfile.ZipFile(zip_directory)\n",
        "dataset_zip.extractall(dataset_directory)\n",
        "dataset_zip.close()\n",
        "\n",
        "train_zip = zipfile.ZipFile(os.path.join(dataset_directory, 'train.zip'))\n",
        "train_zip.extractall(dataset_directory)\n",
        "train_zip.close()\n",
        "\n",
        "test_zip = zipfile.ZipFile(os.path.join(dataset_directory, 'test1.zip'))\n",
        "test_zip.extractall(dataset_directory)\n",
        "test_zip.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "-Wy0FSR2yVMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Dataset 만들기"
      ],
      "metadata": {
        "id": "Tdj_zMEb0Hs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "from torchvision.io import read_image\n",
        "import torchvision\n",
        "\n",
        "dataset_len = len(os.listdir(os.path.join(dataset_directory, 'train'))) #25000\n",
        "test_len = len(os.listdir(os.path.join(dataset_directory, 'test1'))) #12500\n",
        "\n",
        "dog_dir = [f'dog.{i}.jpg' for i in range(12500)]\n",
        "cat_dir = [f'cat.{i}.jpg' for i in range(12500)]  #파일 디렉토리가 dog.i.jpg , cat.i.jpg 로 되어있다.\n",
        "\n",
        "train_annotation = dog_dir + cat_dir                      #같은 폴더에 cat, dog가 동시에 존재\n",
        "test_annotation = [f'{i+1}.jpg' for i in range(12500)]     # 1.jpg, 2.jpg 로 되어있음\n",
        "\n",
        "train_dir = os.path.join(dataset_directory, 'train')\n",
        "test_dir = os.path.join(dataset_directory, 'test1')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CustomDataset(data.Dataset):\n",
        "  def __init__(self, files, root, mode='train', transform = None):\n",
        "    self.files = files\n",
        "    self.root = root\n",
        "    self.mode = mode\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_path = os.path.join(self.root, self.files[index]) # 'C:/Users/Unity/Downloads/CatDog/train/dog.index.jpg\n",
        "    image = read_image(img_path)\n",
        "    if 'cat' in self.files[index]:\n",
        "      label = 0\n",
        "    else:\n",
        "      label = 1\n",
        "\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    \n",
        "    if self.mode == 'train':\n",
        "      return image, label\n",
        "    elif self.mode == 'test':\n",
        "      return index\n",
        "\n"
      ],
      "metadata": {
        "id": "a2prcbUHzhhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "디렉토리에 저장되어있는 데이터셋을 데이터로더를 통해 학습시키기 위해 커스텀 데이터셋을 직접 만들어야한다. 코드를 보면 알겠지만\n",
        "<br>\n",
        "__len__ : 데이터셋 크기 리턴\n",
        "<br>\n",
        "__getitem__ : 메서드가 불릴 때마다 디렉토리에서 이미지 한장과 그 정답을 리턴"
      ],
      "metadata": {
        "id": "mqn3zw0e34Y0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 transform을 정의하고 DataLoader를 만들자"
      ],
      "metadata": {
        "id": "kX-wMboq787g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "train_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((256,256)),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "])\n",
        "test_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((256,256)),\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = CustomDataset(train_annotation, train_dir, mode='train', transform = train_transform)\n",
        "test_datset = CustomDataset(test_annotation, test_dir, mode='test', transform = test_transform)\n",
        "\n",
        "\n",
        "#==============================================================================\n",
        "#여기서부터는 Custom Dataset을 토대로 DataLoader를 정의해야합니다.\n",
        "#이건 이미 다 배운 내용이므로 생략하겠습니다.\n",
        "\n",
        "#정의되어야할 내용: 무작위 셔플을 설정해주시고, 배치 사이즈는 64로 정해주시고, \n",
        "#마지막 64로 나누어떨어지지 않는 배치는 사용하지 않도록 해주세요!\n",
        "#testloader는 셔플을 하시지 않는 걸 추천드립니당\n",
        "\n",
        "#Hint : wk8 분류기 훈련시키기\n",
        "#==============================================================================\n",
        "\n",
        "pass\n"
      ],
      "metadata": {
        "id": "uvPDJrBo03tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 커스텀 모듈 만들기 feat. Subclass Modeling"
      ],
      "metadata": {
        "id": "_qVKd6Ef-sjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN 모듈을 이용해서 여러분이 직접 원하는 형태의 인공지능 모델을 생성해주세요!\n",
        "<br>\n",
        "Subclass 모델링을 사용해주시기 바랍니다!\n",
        "<br>\n",
        "<br>\n",
        "**HINT: wk8_분류기_훈련시키기 or basic_wk9**\n",
        "<br>\n",
        "<br>\n",
        "더 높은 난이도를 원하신다면 : 모듈을 여러개 만들어서 메인 모듈에서 합쳐보세요!"
      ],
      "metadata": {
        "id": "t-rWxTKF-9ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "\n",
        "    pass\n",
        "\n",
        "  def forward(self, x):\n",
        "    pass\n",
        "    #모델의 최종 아웃풋은 2차원 벡터입니다"
      ],
      "metadata": {
        "id": "QNeutdHc07gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "원하는대로 잘 만들었는지 확인해보자."
      ],
      "metadata": {
        "id": "MYy5_k6GAJks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = Model()\n",
        "model.cuda()\n",
        "\n",
        "summary(model, input_size=(3,256,256))"
      ],
      "metadata": {
        "id": "zng5GZcV_4f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model"
      ],
      "metadata": {
        "id": "xk7gWLzXAN2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 만든 모델을 학습해보자!\n",
        "\n",
        "**HINT : wk8_분류기_훈련시키기**"
      ],
      "metadata": {
        "id": "1dfNObHPAgMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, epoch, device, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    \n",
        "    for i in range(epoch):\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for idx, (input, target) in enumerate(dataloader):\n",
        "            \n",
        "            \n",
        "            input = input.to(device)\n",
        "            target = target.to(device)\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "            _, predicted = output.max(1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "\n",
        "        acc = 100 * correct / total\n",
        "        print('train epoch : {} [{}/{}]| loss: {:.3f} | acc: {:.3f}'.format(\n",
        "        i, idx, len(dataloader), train_loss/(idx+1), acc))\n",
        "    \n",
        "    print(\"end of training\")\n"
      ],
      "metadata": {
        "id": "fJZ9fwlDAPdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "만족할만 했다면 뒤의 test로 넘어가고, 아니라면 training의 하이퍼파라미터나 모델을 수정해보자"
      ],
      "metadata": {
        "id": "p-CnJevwAuDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "jf93mpdNA5Wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 대회에 제출하기 위한 test set을 eval 해보자\n",
        "<br>\n",
        "<br>\n",
        "이미 test에 대한 dataloader가 정의되어 있어야합니다! 아니라면 위의 Dataloader 칸으로 올라가서 testloader를 생성해주세요"
      ],
      "metadata": {
        "id": "TyxYy3VvCAWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def predict(model, testloader, device, submission_dir):\n",
        "  model.eval()\n",
        "  sub = pd.read_csv(submission_dir)\n",
        "  with torch.no_grad():\n",
        "    for x, index in testloader:\n",
        "      x.to(device)\n",
        "      pred = model(x)\n",
        "\n",
        "      sub.iloc[index,1]=pred.argmax(pred, dim=1).numpy()        #csv 파일에 각각 정답을 입력하는 것.\n",
        "      \n",
        "  return sub\n"
      ],
      "metadata": {
        "id": "qAhIBV1ZA4Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아 근데...다하고 보니까 이게 submission이 닫혀있네요...제가 인공지능 처음 배웠을 때는 열려있었는데...ㅎ...죄송함다...submission은 못하지만..그래도 방식은 알려드리겠습니다..!"
      ],
      "metadata": {
        "id": "qe-lnyMRHhmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src=\"https://ifh.cc/g/C3j8Xh.jpg\" alt=\"Alternative text\" style=\"width:400px;\" />"
      ],
      "metadata": {
        "id": "6Q1C7gBjIaup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이처럼 kaggle 대회 페이지에 가보면 Submit Predictions라는 버튼이 있습니다. 해당 버튼을 누르면 "
      ],
      "metadata": {
        "id": "YxrBXDQzH8G5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://ifh.cc/g/G4NwBg.png\n",
        "\" alt=\"Alternative text\" style=\"width:300px;\" />"
      ],
      "metadata": {
        "id": "wfPiw474JgTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기에 저장한 submission.csv를 업로드하면 됩니다 아니면 밑의 명령어를 이용해서 kaggle API를 사용해도 됩니다."
      ],
      "metadata": {
        "id": "oZDYmn6IJ6yQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission을 통한 성취감을 보여드리고 싶었는데 시시하게 끝나서 죄송합니다. 하지만, 이 모든 과정을 따라 오셨다면 이제 다른 대회나 프로젝트를 해도 전부 성공하실 수 있을 것입니다."
      ],
      "metadata": {
        "id": "x2cIYyicKHBo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hsk8-DrPGnaN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}